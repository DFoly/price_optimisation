# The name of the bundle. run `databricks bundle schema` to see the full bundle settings schema.
bundle:
  # Do not modify the below line, this autogenerated field is used by the Databricks backend.
  uuid: 6d9dce8e-edc9-4621-85bd-e623676a664d

  name: price_optimisation

variables:
  experiment_name:
    description: Experiment name for the model training.
    default: /Users/${workspace.current_user.userName}/${bundle.target}-price_optimisation-experiment
  model_name:
    description: Model name for the model training.
    default: price_optimisation-model
  catalog_name:
    description: The catalog name to save the trained model
    
include:
  # Resources folder contains ML artifact resources for the ML project that defines model and experiment
  # And workflows resources for the ML project including model training -> validation -> deployment,
  # feature engineering,  batch inference, quality monitoring, metric refresh, alerts and triggering retraining
  - ./resources/batch-inference-workflow-resource.yml
  - ./resources/ml-artifacts-resource.yml
  - ./resources/model-workflow-resource.yml
  - ./resources/feature-engineering-workflow-resource.yml
  # TODO: uncomment once monitoring inference table has been created
  # - ./resources/monitoring-resource.yml

# Deployment Target specific values for workspace
targets:
  dev:  # UC Catalog Name 
    mode: development
    default: true
    variables:
      catalog_name: dev
    workspace:
      # TODO: add dev workspace URL
      host: https://dbc-ac4dc1c9-1a7f.cloud.databricks.com

  staging:
    variables:
      catalog_name: staging
    workspace:
      host: https://dbc-ac4dc1c9-1a7f.cloud.databricks.com

  prod:
    variables:
      catalog_name: prod
    workspace:
      host: https://dbc-ac4dc1c9-1a7f.cloud.databricks.com

  test:
    variables:
      catalog_name: test
    workspace:
      host: https://dbc-ac4dc1c9-1a7f.cloud.databricks.com
